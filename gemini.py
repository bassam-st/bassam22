import json
import logging
import os
import html

from google import genai
from google.genai import types


# IMPORTANT: KEEP THIS COMMENT
# Follow these instructions when using this blueprint:
# - Note that the newest Gemini model series is "gemini-2.5-flash" or gemini-2.5-pro"
#   - do not change this unless explicitly requested by the user

# This API key is from Gemini Developer API Key, not vertex AI API Key
def get_gemini_client():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ù…ÙŠÙ„ Gemini (ÙŠØ¹ÙŠØ¯ None Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ API key)"""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        return None
    return genai.Client(api_key=api_key)


def answer_with_ai(question: str):
    """
    Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø°ÙƒÙŠØ© ÙˆØ¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
    ÙŠØ¹ÙŠØ¯ dict Ù…Ø¹ 'text' Ùˆ 'html' Ø£Ùˆ None Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† API key Ù…ØªÙˆÙØ±Ø§Ù‹.
    """
    try:
        client = get_gemini_client()
        if not client:
            return None
            
        # Ø¨Ù†Ø§Ø¡ prompt Ø°ÙƒÙŠ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        system_prompt = """Ø£Ù†Øª "Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ" - Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¹Ø±Ø¨ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ:
1. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¯Ù‚Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
2. Ø´Ø±Ø­ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø¨Ø³Ø·Ø©
3. ØªÙ‚Ø¯ÙŠÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙˆØ«ÙˆÙ‚Ø© ÙˆÙ…ÙÙŠØ¯Ø©
4. Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù†ØµØ§Ø¦Ø­

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹
- Ø§Ø¬Ø¹Ù„ Ø¥Ø¬Ø§Ø¨ØªÙƒ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙØµÙ„Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¹Ø±Ù Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ØµØ±Ø§Ø­Ø©
- ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø© Ø£Ùˆ Ø§Ù„Ù…Ø¶Ù„Ù„Ø©"""

        prompt = f"{system_prompt}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\n\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=1000,
            )
        )

        if response.text:
            answer_text = response.text.strip()
            
            # ØªÙ†Ø³ÙŠÙ‚ HTML Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©
            safe_question = html.escape(question)
            safe_answer = html.escape(answer_text)
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø£ÙØ¶Ù„
            formatted_answer = safe_answer.replace('\n', '<br>')
            formatted_answer = formatted_answer.replace('- ', '<br>â€¢ ')
            formatted_answer = formatted_answer.replace('. ', '.<br><br>')
            
            html_response = f'''
            <div class="card">
                <h4>ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø³Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ</h4>
                <h5 style="color:#666;">â“ Ø§Ù„Ø³Ø¤Ø§Ù„: {safe_question}</h5>
                <hr>
                <div style="background:#f9f9f9;padding:15px;border-radius:8px;line-height:1.6;">
                    {formatted_answer}
                </div>
                <small style="color:#999;margin-top:10px;display:block;">
                    ğŸ’¡ ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Gemini AI
                </small>
            </div>
            '''
            
            return {
                "text": answer_text, 
                "html": html_response
            }
        else:
            return None
            
    except Exception as e:
        logging.error(f"Ø®Ø·Ø£ ÙÙŠ Gemini AI: {e}")
        error_html = f'''
        <div class="card" style="border-left:4px solid #ff6b6b;">
            <h4>âŒ Ø®Ø·Ø£ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</h4>
            <p>Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.</p>
            <small style="color:#666;">ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {html.escape(str(e))}</small>
        </div>
        '''
        return {
            "text": f"Ø®Ø·Ø£ ÙÙŠ AI: {str(e)}", 
            "html": error_html
        }


def smart_math_help(question: str):
    """
    Ù…Ø³Ø§Ø¹Ø¯Ø© Ø°ÙƒÙŠØ© ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
    """
    try:
        client = get_gemini_client()
        if not client:
            return None
            
        system_prompt = """Ø£Ù†Øª Ù…Ø¯Ø±Ø³ Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø®Ø¨ÙŠØ±. Ø§Ø´Ø±Ø­ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù‡Ù…Ø©:
- Ø§Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ© Ø¨ÙˆØ¶ÙˆØ­
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©
- Ù‚Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ù…Ø´Ø§Ø¨Ù‡Ø© Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
- ØªØ£ÙƒØ¯ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª"""

        prompt = f"{system_prompt}\n\nØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ: {question}\n\nØ§Ù„Ø­Ù„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ:"
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )

        if response.text:
            answer_text = response.text.strip()
            safe_answer = html.escape(answer_text)
            formatted_answer = safe_answer.replace('\n', '<br>')
            
            html_response = f'''
            <div class="card">
                <h4>ğŸ§® Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠ</h4>
                <hr>
                <div style="background:#f0f8ff;padding:15px;border-radius:8px;line-height:1.8;">
                    {formatted_answer}
                </div>
            </div>
            '''
            
            return {
                "text": answer_text, 
                "html": html_response
            }
        else:
            return None
            
    except Exception as e:
        logging.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª: {e}")
        return None


def is_gemini_available() -> bool:
    """ÙØ­Øµ ØªÙˆÙØ± Gemini API"""
    return os.environ.get("GEMINI_API_KEY") is not None
